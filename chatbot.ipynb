{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **QA Chatbot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et0S2YGfaa91",
        "outputId": "012aca1a-cba6-4b95-d3ff-12906086436c"
      },
      "outputs": [],
      "source": [
        "# %pip -q install langchain openai tiktoken chromadb google-search-results langchainhub\n",
        "# %pip show langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory, ReadOnlySharedMemory\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.agents import AgentType\n",
        "from langchain.tools import BaseTool\n",
        "from langchain import SerpAPIWrapper\n",
        "from langchain.utilities import SerpAPIWrapper\n",
        "from langchain import hub\n",
        "from langchain.agents import create_openai_functions_agent\n",
        "from langchain import LLMMathChain\n",
        "import os\n",
        "import config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OB_Ty3LzbIOy"
      },
      "outputs": [],
      "source": [
        "API_KEY = os.environ[\"OPENAI_API_KEY\"] = config.OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZAb6tNPDb6jx"
      },
      "outputs": [],
      "source": [
        "# Definir constantes\n",
        "CHROMA_PATH = \"chroma\"  # Ruta para la base de datos de Chroma\n",
        "DATA_PATH = \"./\"  # Ruta al directorio que contiene los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Y5KyXHGmcPiJ"
      },
      "outputs": [],
      "source": [
        "file_pattern = 'embeddings.md'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instanciación del cargador de directorio con el patrón de archivo especificado\n",
        "loader = DirectoryLoader(DATA_PATH, glob=file_pattern,\n",
        "                         loader_cls=lambda path: TextLoader(path, encoding='utf-8'))\n",
        "\n",
        "# Carga de documentos utilizando el cargador\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qYHRNKm3ccfR"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=200)\n",
        "texts = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUk6zITpctdB",
        "outputId": "5a22f8ec-90bf-4444-e5ad-09871fcacdc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "141"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqxkFEY_cwGA",
        "outputId": "0b4345d9-977c-4d56-fb9f-7084453cb096"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='# Plan de Estudios: Ingeniería en Datos e Inteligencia Organizacional (Plan 2016)\\n\\n## Créditos Totales\\n\\n404 créditos\\n\\n## Descripción General', metadata={'source': 'embeddings.md'})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ik4zov_c3kX",
        "outputId": "8e268c74-12ee-4130-a610-c46c47691ebc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Marco\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "# Directorio de persistencia para almacenar la base de datos\n",
        "persist_directory = 'db'\n",
        "\n",
        "# Seleccionamos OpenAI embeddings para la generación de vectores\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "# Creamos una instancia de Chroma para generar vectores a partir de documentos\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=texts,  # Los documentos de texto a procesar para la generación de vectores\n",
        "    embedding=embedding,  # El método de embedding a utilizar para generar vectores\n",
        "    persist_directory=persist_directory  # Directorio donde se almacenará la base de datos de vectores\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AubE1Q4ydEyP"
      },
      "outputs": [],
      "source": [
        "vectordb.persist()\n",
        "vectordb = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MC819YhRdHqP"
      },
      "outputs": [],
      "source": [
        "# Creación de una nueva instancia de Chroma, para cargar una base de datos existente\n",
        "vectordb = Chroma(\n",
        "    persist_directory=persist_directory,  # Directorio de persistencia de la base de datos de vectores\n",
        "    embedding_function=embedding  # Función de embedding a utilizar\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "73fmDU6JdgGP"
      },
      "outputs": [],
      "source": [
        "# Convertir la base de datos de vectores en un objeto retriever\n",
        "retriever = vectordb.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CKlfTseIdiD_"
      },
      "outputs": [],
      "source": [
        "# Usando el objeto retriever para obtener documentos relevantes para una consulta específica\n",
        "docs = retriever.get_relevant_documents(\"Total de creditos de la carrera\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k69cCOwJEMVe",
        "outputId": "bef1c824-510b-42b7-93dd-5b5e514630ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='404 créditos\\n\\n## Descripción General\\n\\nTodas las materias de la Ingeniería en Datos e Inteligencia Organizacional tienen un ciclo, una clave, un nombre, un número de créditos, un tipo y una academia.', metadata={'source': 'embeddings.md'}),\n",
              " Document(page_content='# Plan de Estudios: Ingeniería en Datos e Inteligencia Organizacional (Plan 2016)\\n\\n## Créditos Totales\\n\\n404 créditos\\n\\n## Descripción General', metadata={'source': 'embeddings.md'}),\n",
              " Document(page_content='el plan de estudios, los 2 talleres (uno artístico/cucural y uno deportivo), tópicos 2, nivel 6 del tercer idioma y el servicio social liberado. Es importante cubrir el total de créditos por sección.', metadata={'source': 'embeddings.md'}),\n",
              " Document(page_content='Durante el tercer ciclo debes cargar y aprobar todas las materias basicas.\\n\\nLas materias de Elección Libre se juntan en el ciclo 3 y 4, se deben reunir 48 creditos de las materias de Elección Libre.', metadata={'source': 'embeddings.md'})]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seDiUecLdm8_",
        "outputId": "01908860-37bc-4b49-b733-0c32335b2eca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "WS1FpWaxduN-"
      },
      "outputs": [],
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Z20zuX3Ddwrm",
        "outputId": "872de391-59ca-4c3f-8819-d3bf612e1b84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'similarity'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.search_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41SVHwnSdy_-",
        "outputId": "2bc4951d-5afe-4379-87f2-444718d72ba7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'k': 2}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.search_kwargs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Xna7w9PBd13-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Marco\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "# Creación de un objeto RetrievalQA a partir de un tipo de cadena específico\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=OpenAI(),  # Modelo de lenguaje a utilizar para la generación de respuestas\n",
        "    chain_type=\"stuff\",  # Tipo de cadena (podría ser una configuración específica para el QA)\n",
        "    retriever=retriever,  # Objeto retriever utilizado para recuperar documentos relevantes\n",
        "    return_source_documents=True  # Especifica si se deben devolver los documentos de origen junto con las respuestas\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "laT470VRd5An"
      },
      "outputs": [],
      "source": [
        "def process_llm_response(llm_response):\n",
        "    # Imprimir la respuesta generada por el modelo de lenguaje\n",
        "    print(llm_response['result'])\n",
        "\n",
        "    # Imprimir la sección de fuentes de la respuesta\n",
        "    print('\\n\\nSources:')\n",
        "\n",
        "    # Iterar sobre cada fuente en los documentos de origen asociados con la respuesta\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        # Imprimir la fuente de cada documento de origen\n",
        "        print(source.metadata['source'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pruebas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-UyOw35d70O",
        "outputId": "7dee1c7a-277b-42dd-9e2e-ad432e075ec2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Marco\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Debes cargar primero y aprobar Física Clásica antes de Electricidad y Magnetismo, ya que es una recomendación para el orden de carga en Ciencias Básicas.\n",
            "\n",
            "\n",
            "Sources:\n",
            "embeddings.md\n",
            "embeddings.md\n"
          ]
        }
      ],
      "source": [
        "# Consulta específica\n",
        "query = \"Quiero cargar Electricidad y magnetismo, ¿qué debo hacer?\"\n",
        "\n",
        "# Obtener la respuesta del modelo de pregunta-respuesta\n",
        "llm_response = qa_chain(query)\n",
        "\n",
        "# Procesar la respuesta utilizando la función process_llm_response\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQ0N8G_be6kk",
        "outputId": "469d762e-d2c7-4389-d100-ee015f6c1900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Se recomienda cargar primero y aprobar \"Cálculo Diferencial\" antes de \"Cálculo Integral\".\n",
            "\n",
            "\n",
            "Sources:\n",
            "embeddings.md\n",
            "embeddings.md\n"
          ]
        }
      ],
      "source": [
        "query = \"Quiero  cargar Calculo Integral, que debo hacer?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1ft3Dc0fAps",
        "outputId": "a940e3f2-a3cc-4a51-82f0-4c3e4f5890e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Existen 4 ciclos: Ciclo 1, Ciclo 2, Ciclo 3 y Ciclo 4.\n",
            "\n",
            "\n",
            "Sources:\n",
            "embeddings.md\n",
            "embeddings.md\n"
          ]
        }
      ],
      "source": [
        "query = \"cuantos ciclos son?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqR162M7fI50",
        "outputId": "eada7779-daa0-4ad2-d3eb-91ee6e8f47b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " La clave de la materia Pensamiento crítico para ingeniería es ID0160 y pertenece al ciclo 1.\n",
            "\n",
            "\n",
            "Sources:\n",
            "embeddings.md\n",
            "embeddings.md\n"
          ]
        }
      ],
      "source": [
        "query = \"cual es la clave de la materia Pensamiento crítico para ingeniería y de que ciclo es?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kvqKkfVmyx6",
        "outputId": "83c462a3-8481-43b1-d68f-de05e1c54726"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Durante el primer ciclo debes aprobar todas las materias básicas y al menos 2 de Elección Libre antes de cargar Aprendizaje Estadístico. Durante el segundo ciclo, debes hacer lo mismo antes de cargar Aprendizaje Estadístico.\n",
            "\n",
            "\n",
            "Sources:\n",
            "embeddings.md\n",
            "embeddings.md\n"
          ]
        }
      ],
      "source": [
        "query = \"¿cuantas materias y cuales debo aprobar antes de cargar Aprendizaje Estadistico?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYH60FJLkdnW",
        "outputId": "b9852466-7675-42c2-c2ba-4500396343cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " En cada ciclo debes aprobar todas las materias basicas y al menos 2 de Eleccion Libre antes de cargar Ecuaciones Diferenciales. Por lo tanto, en total debes aprobar 6 materias basicas y 2 de Eleccion Libre antes de cargar Ecuaciones Diferenciales. Las materias basicas de ciclo 2 y ciclo 3 se desconocen, pero es posible que Ecuaciones Diferenciales sea una materia del ciclo 4 o superior. \n",
            "\n",
            "\n",
            "Sources:\n",
            "embeddings.md\n",
            "embeddings.md\n"
          ]
        }
      ],
      "source": [
        "query = \"¿cuantas materias y cuales debo aprobar antes de cargar Ecuaciones Diferenciales?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DylrOuXogKV9",
        "outputId": "fe5f0f8f-0f25-4459-957b-9f947c118c5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " No sé, necesito más información.\n",
            "\n",
            "\n",
            "Sources:\n",
            "embeddings.md\n",
            "embeddings.md\n"
          ]
        }
      ],
      "source": [
        "query = \"cuantos son los creditos totales de la carrera?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvDBtZUDmPFC",
        "outputId": "18f5248c-3c9e-4b4b-fb86-26b542c98baf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " La materia de Aprendizaje Estadístico es una asignatura básica en el Ciclo 3, con una clave de materia ID0309 y un valor de 6 créditos. Esta materia se enfoca en el aprendizaje de técnicas estadísticas avanzadas para la toma de decisiones y análisis de datos. Es una continuación de la materia de Estadística Analítica en el Ciclo 2, con clave de materia IL0204 y 8 créditos.\n",
            "\n",
            "\n",
            "Sources:\n",
            "embeddings.md\n",
            "embeddings.md\n"
          ]
        }
      ],
      "source": [
        "query = \" Hablame de la materia de Aprendizaje Estadistico\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXtc9D1Zmux_",
        "outputId": "f8c1cbf8-6abb-46a4-8046-4b93d7bd6683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "La clave de esa materia es IT0322.\n",
            "\n",
            "\n",
            "Sources:\n",
            "embeddings.md\n",
            "embeddings.md\n"
          ]
        }
      ],
      "source": [
        "query = \" cual es la clave de esa materia?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Agente: Google Search Results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Marco\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "llm = ChatOpenAI(temperature=0, max_tokens=1000, model=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"SERPAPI_API_KEY\"] = config.SERPAPI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Agente: LLM MathChain**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'search' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[37], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m tools \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     Tool(\n\u001b[0;32m      3\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQA System\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m         func\u001b[38;5;241m=\u001b[39mqa_chain\u001b[38;5;241m.\u001b[39mrun,\n\u001b[0;32m      5\u001b[0m         description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mÚtil cuando necesitas responder preguntas sobre El mapa curricular de IDeIO. La entrada debe ser una pregunta completamente formulada.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m     ),\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m     Tool(\n\u001b[0;32m      9\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBackup QA Google Search\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m---> 10\u001b[0m         func\u001b[38;5;241m=\u001b[39m\u001b[43msearch\u001b[49m\u001b[38;5;241m.\u001b[39mrun,\n\u001b[0;32m     11\u001b[0m         description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mÚtil cuando necesitas responder preguntas sobre El mapa curricular de IDeIO, pero solo cuando el Sistema de Preguntas y Respuestas de El mapa curricular de IDeIO no pudo responder la consulta. La entrada debe ser una pregunta completamente formulada.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m     ),\n\u001b[0;32m     13\u001b[0m     Tool(\n\u001b[0;32m     14\u001b[0m         func\u001b[38;5;241m=\u001b[39mllm_math_chain\u001b[38;5;241m.\u001b[39mrun,\n\u001b[0;32m     15\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculadora\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m         description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHerramienta que suma las materias y suma los creditos de las materias \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m     ),\n\u001b[0;32m     18\u001b[0m ]\n",
            "\u001b[1;31mNameError\u001b[0m: name 'search' is not defined"
          ]
        }
      ],
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"QA System\",\n",
        "        func=qa_chain.run,\n",
        "        description=\"Útil cuando necesitas responder preguntas sobre El mapa curricular de IDeIO. La entrada debe ser una pregunta completamente formulada.\"\n",
        "    ),\n",
        "\n",
        "    Tool(\n",
        "        name=\"Backup QA Google Search\",\n",
        "        func=search.run,\n",
        "        description=\"Útil cuando necesitas responder preguntas sobre El mapa curricular de IDeIO, pero solo cuando el Sistema de Preguntas y Respuestas de El mapa curricular de IDeIO no pudo responder la consulta. La entrada debe ser una pregunta completamente formulada.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        func=llm_math_chain.run,\n",
        "        name=\"Calculadora\",\n",
        "        description=\"Herramienta que suma las materias y suma los creditos de las materias \",\n",
        "    ),\n",
        "]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
